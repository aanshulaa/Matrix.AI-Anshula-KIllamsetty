{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CODES REQUIRED TO DO THIS COMPUTER VISION ASSIGNMENT"
      ],
      "metadata": {
        "id": "hBtnKDWZS-dA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1)"
      ],
      "metadata": {
        "id": "jz1pyR4STccR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "# Provide the absolute path to your dataset directory\n",
        "dataset_path = '/content/drive/MyDrive/yolov9/deep_fashion.tar'\n",
        "\n",
        "if os.path.exists(dataset_path):\n",
        "    # List all files in the dataset directory\n",
        "    image_files = [f for f in os.listdir(dataset_path) if os.path.isfile(os.path.join(dataset_path, f))]\n",
        "\n",
        "    # Randomly selecting 500 images for training\n",
        "    random.shuffle(image_files)\n",
        "    selected_images = image_files[:500]\n",
        "\n",
        "    # Define the sizes for train, validation, and test splits\n",
        "    train_size = int(0.7 * len(selected_images))\n",
        "    val_size = int(0.2 * len(selected_images))\n",
        "    test_size = len(selected_images) - train_size - val_size\n",
        "\n",
        "    # Divide the selected images into train, validation, and test sets\n",
        "    train_images = selected_images[:train_size]\n",
        "    val_images = selected_images[train_size:train_size + val_size]\n",
        "    test_images = selected_images[train_size + val_size:]\n",
        "else:\n",
        "    print(f\"Directory '{dataset_path}' does not exist.\")\n",
        "\n",
        "    # Copy images to train, validation, and test directories\n",
        "for img in train_images:\n",
        "    shutil.copy(os.path.join(dataset_path, img), os.path.join(sample_dataset_path, \"train\"))\n",
        "\n",
        "for img in val_images:\n",
        "    shutil.copy(os.path.join(dataset_path, img), os.path.join(sample_dataset_path, \"val\"))\n",
        "\n",
        "for img in test_images:\n",
        "    shutil.copy(os.path.join(dataset_path, img), os.path.join(sample_dataset_path, \"test\"))"
      ],
      "metadata": {
        "id": "8qF4Gar7S_dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python code snippet checks for the existence of a dataset directory specified by dataset_path. If the directory exists, it lists all files in the directory, randomly selects 500 images from the dataset for training, and divides them into train, validation, and test sets based on the specified ratios (70%, 20%, 10% respectively). The code uses the os and random modules for file operations and random selection, ensuring a balanced split of images for training and evaluation purposes."
      ],
      "metadata": {
        "id": "p7ESSyr5TDaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)\n"
      ],
      "metadata": {
        "id": "stDxT6QxTemP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet contains functions convert_to_coco and convert_to_yolo, which are placeholders for converting a dataset into MSCOCO and YOLO format, respectively. Here's the name and usage breakdown:\n",
        "\n",
        "Name:\n",
        "\n",
        "convert_to_coco: Converts a dataset to MSCOCO format.\n",
        "convert_to_yolo: Converts MSCOCO annotations to YOLO format.\n",
        "Usage:\n",
        "\n",
        "convert_to_coco(images_dir, annotations_dir, coco_output_dir): This function takes the directory paths of images, annotations, and the output directory for MSCOCO format. However, the actual conversion logic is not implemented (pass statement), so it needs to be filled with code to perform the conversion.\n",
        "convert_to_yolo(coco_annotations_dir, yolo_output_dir): Similarly, this function takes the directory paths of MSCOCO annotations and the output directory for YOLO format. It also requires implementation for the conversion process."
      ],
      "metadata": {
        "id": "hYZR8sruTHro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def convert_to_coco(images_dir, annotations_dir, coco_output_dir):\n",
        "\n",
        "    pass\n",
        "\n",
        "def convert_to_yolo(coco_annotations_dir, yolo_output_dir):\n",
        "\n",
        "    pass\n",
        "\n",
        "# Paths\n",
        "sample_dataset_path = \"/content/sample_deep_fashion\"\n",
        "coco_output_dir = \"/content/sample_deep_fashion_coco\"\n",
        "yolo_output_dir = \"/content/sample_deep_fashion_yolo\"\n",
        "\n",
        "# Convert to MSCOCO format\n",
        "convert_to_coco(sample_dataset_path, coco_output_dir, coco_output_dir)\n",
        "\n",
        "# Convert to YOLO format\n",
        "convert_to_yolo(coco_output_dir, yolo_output_dir)\n"
      ],
      "metadata": {
        "id": "i5PrzAFKTDQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3)"
      ],
      "metadata": {
        "id": "V3WZLlJATkKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: `convert_to_coco`\n",
        "\n",
        "Usage: This code snippet defines a function `convert_to_coco` that takes two arguments:\n",
        "- `images_dir`: The directory path containing images.\n",
        "- `coco_output_dir`: The directory where the MSCOCO format output will be saved.\n",
        "\n",
        "This function is designed to convert a dataset into MSCOCO format. It creates a JSON structure representing the MSCOCO dataset with fields for images, annotations, and categories. The actual implementation of the function includes iterating through images in the specified directory, extracting metadata such as image ID, file name, height, width, and bounding box coordinates. It then constructs the MSCOCO JSON structure and writes it to a JSON file in the specified output directory.\n",
        "\n",
        "Note: The function's implementation lacks specific details such as image dimensions (`img_height` and `img_width`), bounding box coordinates (`x, y, w, h`), and category information, which need to be provided or computed based on the dataset being processed."
      ],
      "metadata": {
        "id": "LkOn2cKUTl0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def convert_to_coco(images_dir, coco_output_dir):\n",
        "    coco_data = {\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": []  # Define your categories here\n",
        "    }\n",
        "\n",
        "    # Iterate through images\n",
        "    for idx, img_filename in enumerate(os.listdir(images_dir)):\n",
        "        img_id = idx + 1  # Unique ID for each image\n",
        "\n",
        "        # Add image information\n",
        "        img_info = {\n",
        "            \"id\": img_id,\n",
        "            \"file_name\": img_filename,\n",
        "            \"height\": img_height,  # Height of the image\n",
        "            \"width\": img_width,    # Width of the image\n",
        "            # Add other image metadata if available\n",
        "        }\n",
        "        coco_data[\"images\"].append(img_info)\n",
        "\n",
        "        # Add annotation information (example)\n",
        "        annotations = [\n",
        "            {\n",
        "                \"id\": 1,          # Unique ID for the annotation\n",
        "                \"image_id\": img_id,\n",
        "                \"category_id\": 1, # Category ID\n",
        "                \"bbox\": [x, y, w, h],  # Bounding box coordinates [xmin, ymin, width, height]\n",
        "                \"segmentation\": [],    # Segmentation mask if available\n",
        "                \"area\": w * h,    # Area of the bounding box\n",
        "                \"iscrowd\": 0      # 0 for individual objects, 1 for crowd\n",
        "            }\n",
        "            # Add other annotations for the image if available\n",
        "        ]\n",
        "        coco_data[\"annotations\"].extend(annotations)\n",
        "\n",
        "    # Write data to JSON file\n",
        "    with open(os.path.join(coco_output_dir, \"/content/deep_fashion/annotations/instances_train2024.json\"), \"w\") as f:\n",
        "        json.dump(coco_data, f)\n"
      ],
      "metadata": {
        "id": "kE6u5s4kTrKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4)"
      ],
      "metadata": {
        "id": "9pHCkuKrUNhi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: YOLOv9-c Model Conversion and Optimization\n",
        "\n",
        "Description: This code segment performs the conversion and optimization of a trained YOLOv9-c model for deployment using OpenVINO. Here's a breakdown of the steps:\n",
        "\n",
        "Loading the Trained Model: The code first loads a pre-trained YOLOv9-c model using PyTorch.\n",
        "\n",
        "Conversion to ONNX Format: The torch.onnx.export function is used to convert the PyTorch model to the ONNX format. This step generates an ONNX model file (yolov9-c.onnx) that represents the YOLOv9-c model in a format compatible with OpenVINO.\n",
        "\n",
        "Optimization for OpenVINO: The script then optimizes the ONNX model for deployment on Intel hardware using the OpenVINO Model Optimizer (mo.py). The Model Optimizer takes the ONNX model (yolov9-c.onnx) as input and specifies the output directory (openvino_models) for the optimized OpenVINO model files. Additionally, it specifies the data type (FP16) for optimization, which is the 16-bit floating-point precision format commonly used for neural network inference.\n",
        "\n",
        "Overall, this code snippet automates the process of converting a PyTorch YOLOv9-c model to the ONNX format and then optimizing it for deployment using OpenVINO, facilitating efficient deployment on Intel-based hardware for inference tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "XqlZeCgDUNW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Load trained PyTorch YOLOv9-c model\n",
        "model = torch.load(\"yolov9-c.pth\")\n",
        "\n",
        "# Convert to ONNX format\n",
        "torch.onnx.export(model, torch.randn(1, 3, 416, 416), \"yolov9-c.onnx\")\n",
        "\n",
        "# Optimize for OpenVINO\n",
        "!mo.py --input_model yolov9-c.onnx --data_type FP16 --output_dir openvino_models\n"
      ],
      "metadata": {
        "id": "YuxAzNejUOQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5)"
      ],
      "metadata": {
        "id": "lxBOxDQuUdO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Dockerfile for GPU-based Training and Inference Environment\n",
        "\n",
        "Description: This Dockerfile sets up a Docker image for a GPU-based training and inference environment, specifically tailored for deep learning tasks using frameworks like PyTorch, torchvision, and OpenVINO. Here's a breakdown of the steps:\n",
        "\n",
        "1. **Base Image**: The Dockerfile starts with the `nvidia/cuda:11.1-cudnn8-runtime-ubuntu20.04` base image, which provides CUDA and cuDNN support for GPU acceleration.\n",
        "\n",
        "2. **Package Installation**: It updates the package lists and installs essential packages like Python 3 and pip3 for package management within the Docker container.\n",
        "\n",
        "3. **Python Packages**: The Dockerfile uses pip3 to install the necessary Python packages required for deep learning, including `torch` (PyTorch), `torchvision` (PyTorch's image and video package), and `openvino` (Intel's OpenVINO toolkit for deep learning inference optimization).\n",
        "\n",
        "4. **Copying Scripts**: The Dockerfile copies the training (`train.py`) and inference (`inference.py`) scripts into the `/app/` directory within the Docker container.\n",
        "\n",
        "5. **Working Directory**: It sets the working directory to `/app/`, where the training and inference scripts are located. This ensures that any commands executed within the Docker container will operate relative to this directory.\n",
        "\n",
        "Overall, this Dockerfile streamlines the setup of a GPU-enabled environment for deep learning tasks, providing the necessary tools and dependencies to run training and inference scripts efficiently using PyTorch, torchvision, and OpenVINO."
      ],
      "metadata": {
        "id": "zbzy6fHcUdLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FROM nvidia/cuda:11.1-cudnn8-runtime-ubuntu20.04\n",
        "\n",
        "# Install required packages\n",
        "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
        "        python3 \\\n",
        "        python3-pip \\\n",
        "        && \\\n",
        "    apt-get clean && \\\n",
        "    rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "# Install required Python packages\n",
        "RUN pip3 install torch torchvision openvino\n",
        "\n",
        "# Copy your training and inference scripts\n",
        "COPY train.py /app/\n",
        "COPY inference.py /app/\n",
        "\n",
        "WORKDIR /app\n"
      ],
      "metadata": {
        "id": "VEH98PQtUeCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6)"
      ],
      "metadata": {
        "id": "tYesFgYHVCAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: Setting Up and Running PyLint for Code Quality Checking\n",
        "\n",
        "Description: This code snippet outlines the steps to install and use PyLint, a tool for analyzing Python code quality. Here's a breakdown of the commands:\n",
        "\n",
        "1. **Install PyLint**: The first command installs PyLint using pip, a Python package manager. PyLint is a widely used tool for checking Python code against coding standards and identifying potential issues such as syntax errors, style violations, and code smells.\n",
        "\n",
        "2. **Run PyLint**: Once PyLint is installed, the second command runs PyLint on the Python scripts `train.py` and `inference.py`. PyLint examines the code and generates a report highlighting any detected issues, providing suggestions for improving code quality and adherence to coding standards.\n",
        "\n",
        "3. **Create README.md**: The final step involves creating a README.md file. This file typically contains information about the solution, approach, instructions for running the code, and any other relevant details that users or developers need to know about the project.\n",
        "\n",
        "Overall, this code segment facilitates code quality checking using PyLint and ensures that the project documentation (README.md) is in place to guide users on using and understanding the codebase."
      ],
      "metadata": {
        "id": "GVViG8ZYVB2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyLint\n",
        "pip install pylint\n",
        "\n",
        "# Run PyLint on your Python scripts\n",
        "pylint train.py inference.py\n",
        "\n",
        "# Create a README.md file explaining your solution, approach, and how to run the code\n"
      ],
      "metadata": {
        "id": "Fax6eZdjVChI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "isxlWNdSVOfY"
      }
    }
  ]
}